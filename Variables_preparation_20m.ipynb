{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593d265c-39b5-495e-a9dd-fb173db00378",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c68fcf-17af-4e98-bdc9-1678a09d8674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from Turbulence_processing.Scaling import *\n",
    "from pyproj import Proj, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2a2af5-4bbf-400d-b67b-c5a29ba7f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_times(ds):\n",
    "    hour = ds.time.dt.hour\n",
    "    night = (hour >= 19) | (hour <= 6)\n",
    "    day = (hour >= 8) & (hour <= 17)\n",
    "    return night, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93420b0-53ff-4a1e-9133-d32f6121bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations dictionary\n",
    "# -------------------\n",
    "# open csv\n",
    "stations = pd.read_csv(\"Perdigao_station.csv\")\n",
    "tower_names = list(stations.groupby(by=\"Name\").groups.keys())\n",
    "# export to dictionary\n",
    "tower_dict = {}\n",
    "for name in tower_names:\n",
    "    # single tower dictionary\n",
    "    station = stations[stations[\"Name\"] == name]\n",
    "    t_dict = {\n",
    "        \"name\": name,\n",
    "        \"lat\": station.iloc[0][\"Latitude\"],\n",
    "        \"lon\": station.iloc[0][\"Longitude\"],\n",
    "        \"east\": station.iloc[0][\"East\"],\n",
    "        \"north\": station.iloc[0][\"North\"],\n",
    "        \"height\": station.iloc[0][\"Tower_height\"],\n",
    "        \"heights_sonic\": station[station[\"Equipment\"] == \"3D Sonic anemometer\"][\n",
    "            \"height\"\n",
    "        ].values,\n",
    "        \"heights_ht\": station[\n",
    "            station[\"Equipment\"] == \"Air temperature and humidity sensor\"\n",
    "        ][\"height\"].values,\n",
    "        \"heights_bar\": station[station[\"Equipment\"] == \"Barometer\"][\"height\"].values,\n",
    "    }\n",
    "    tower_dict[name] = t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f06260-bd15-4637-b517-572d810207ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform coordinates from UTM to a local coordinate system and vice versa\n",
    "def transform_UTM_to_local(east, north, inverse=False):\n",
    "    # Create an array of coordinates\n",
    "    coords = np.array([east, north])\n",
    "\n",
    "    # Define a rotation matrix for coordinate transformation\n",
    "    rot = np.array(\n",
    "        [\n",
    "            [np.cos(np.pi / 4), np.sin(np.pi / 4)],\n",
    "            [-np.sin(np.pi / 4), np.cos(np.pi / 4)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the center coordinates for the local coordinate system\n",
    "    center = np.array([608250, 4396621])\n",
    "\n",
    "    # two versions for single and array\n",
    "    if len(np.shape(east)) == 0:\n",
    "        # Apply the transformation from UTM to local coordinates if inverse is False\n",
    "        if not inverse:\n",
    "            coords = rot @ (coords - center).T\n",
    "        # Apply the inverse transformation from local coordinates to UTM if inverse is True\n",
    "        else:\n",
    "            coords = rot.T @ coords.T + center.T\n",
    "        return coords\n",
    "\n",
    "    else:\n",
    "        coords = np.column_stack([east, north])\n",
    "        new_coords = []\n",
    "        for i in range(len(coords)):\n",
    "            # Apply the transformation from UTM to local coordinates if inverse is False\n",
    "            if not inverse:\n",
    "                new_coords.append(rot @ (coords[i] - center).T)\n",
    "            # Apply the inverse transformation from local coordinates to UTM if inverse is True\n",
    "            else:\n",
    "                new_coords.append(rot.T @ coords[i].T + center.T)\n",
    "        return np.array(new_coords)\n",
    "\n",
    "\n",
    "ETRS_UTM_transform = Transformer.from_crs(\"EPSG:3763\", \"EPSG:32629\").transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0226e1-0ee8-4d3f-980e-d52b066e00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_coords(tower):\n",
    "    # tower coordinates\n",
    "    E = tower[\"east\"]\n",
    "    N = tower[\"north\"]\n",
    "    x_t, y_t = transform_UTM_to_local(*ETRS_UTM_transform(E, N))\n",
    "    # coordinates offset\n",
    "    x_t += 239\n",
    "    y_t += 68\n",
    "    return (x_t, y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f10d37-d913-47da-a2e7-2d62ef66ef8a",
   "metadata": {},
   "source": [
    "## open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e1123e9-eff0-4402-9750-9d686a47b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open and prepare dataset\n",
    "def open_prepare(tower_name, time_avg):\n",
    "    # -------------------\n",
    "    #  OPEN DATA\n",
    "    # footprint\n",
    "    ffp_stat = xr.open_dataset(\n",
    "        f\"../../../../../Dataset/Perdigao/Footprint terrain analysis/results/ffp_terrain_{time_avg}_{tower_name}.nc\"\n",
    "    )\n",
    "    # transect\n",
    "    trans_stat = xr.open_dataset(\n",
    "        f\"../../../../../Dataset/Perdigao/upwind_transect_analysis/results/trans_terrain_{time_avg}_{tower_name}.nc\"\n",
    "    )\n",
    "    ds = xr.open_dataset(\n",
    "        f\"../../../../../Dataset/Perdigao/postprocessed_{time_avg}/Perdigao_statistics_{time_avg}_{tower_name}.nc\"\n",
    "    )\n",
    "    # BLH\n",
    "    BLH = xr.open_dataset(\"../../../../../Dataset/Perdigao/BLH_ERA.nc\")\n",
    "    BLH = BLH.interp(time=ds.time.data)\n",
    "    BLH = xr.DataArray(data=BLH.BLH.data.flatten(), coords={\"time\": BLH.time})\n",
    "\n",
    "    # PROCESS\n",
    "    # ---------------------------------------------------\n",
    "    # find sonic height\n",
    "    idx_h = [i for i, x in enumerate(bool_20m_array) if x][0]\n",
    "    h = heights[idx_h]\n",
    "    ds = ds.sel(heights=h)\n",
    "    ffp_stat = ffp_stat.sel(heights=h)\n",
    "    trans_stat = trans_stat.sel(heights=h)\n",
    "    \n",
    "    # assign spatial coordinates\n",
    "    x_t, y_t = get_local_coords(tower)\n",
    "    ds = ds.assign_coords({\"x\": x_t, \"y\": y_t})\n",
    "\n",
    "    # select daytime\n",
    "    ds = ds.where(select_times(ds)[1], drop=True)\n",
    "    BLH = BLH.where(select_times(BLH)[1], drop=True)\n",
    "    ffp_stat = ffp_stat.where(select_times(ffp_stat)[1], drop=True)\n",
    "    trans_stat = trans_stat.where(select_times(trans_stat)[1], drop=True)\n",
    "\n",
    "    # anisotropy and gradients\n",
    "    bary, RGB = Anisotropy.Anisotropy(ds, one_sonic=True)\n",
    "    ds = ds.assign(\n",
    "        xb=(['time'],bary[0]),\n",
    "        yb=(['time'],bary[1])\n",
    "    )\n",
    "\n",
    "    # ADD VARIABLES\n",
    "    # --------------------------------------------\n",
    "    # Obukhov length\n",
    "    L = -ds.ustar**3 * ds.meanT / (0.4 * 9.81 * ds.wT)\n",
    "    # free convection velocity\n",
    "    wfc = (9.81 / ds.meanT * ds.wT * BLH) ** (1 / 3)\n",
    "    # budget terms\n",
    "    tkeprod_buoy = 9.81 / ds.meanT * ds.wT\n",
    "\n",
    "    ds = ds.assign(\n",
    "        # height / BLH\n",
    "        z_zi=ds.heights / BLH,\n",
    "        # zeta stability parameter\n",
    "        zeta=-1 / L * ds.heights,\n",
    "        # Saleski roll to cell\n",
    "        zi_L=BLH / L,\n",
    "        # zeta with blh (heisel chamecki 23)\n",
    "        zeta_blh=1 / np.sqrt(-L * BLH) * ds.heights,\n",
    "        # z / z0\n",
    "        z_z0=ds.heights / ds.z0,\n",
    "        # integral time  / memory\n",
    "        tw_te=ds.intlenW / ds.meanU / ds.tke * ds.epsU,\n",
    "        tw_te_u_wfc=ds.intlenW / wfc / ds.tke * ds.epsU,\n",
    "        tw_te_u_ust=ds.intlenW / ds.ustar / ds.tke * ds.epsU,\n",
    "        # rapid distortion\n",
    "        rapid_dist_neut=ds.ustar / 0.4 / ds.heights * ds.tke / ds.epsU,\n",
    "        # free convection velocity\n",
    "        U_wfc=ds.meanU / wfc,\n",
    "        # dynamical stuff\n",
    "        U_ust=ds.meanU / ds.ustar,\n",
    "        # tke and stress budget\n",
    "        # production\n",
    "        tkeprod_buoy_eps=tkeprod_buoy / ds.epsU,\n",
    "        # lengthscales from Ghannam et al 2018\n",
    "        ust3_eps_z=ds.ustar**3 / ds.epsU / ds.heights,\n",
    "        # moments\n",
    "        kurt_u=ds.uuuu / ds.uu**2,\n",
    "        kurt_v=ds.vvvv / ds.vv**2,\n",
    "        kurt_w=ds.wwww / ds.ww**2,\n",
    "        skew_u=ds.uuu / ds.uu**1.5,\n",
    "        skew_v=ds.vvv / ds.vv**1.5,\n",
    "        skew_w=ds.www / ds.ww**1.5,\n",
    "        uv_tke=ds.uv / ds.tke,\n",
    "        vw_tke=ds.vw / ds.tke,\n",
    "        uw_tke=ds.uw / ds.tke,\n",
    "        uT_wT=ds.uT / ds.wT,\n",
    "        vT_wT=ds.vT / ds.wT,\n",
    "        vw_uw=ds.vw / ds.uw,\n",
    "        uv_uw=ds.uv / ds.uw,\n",
    "        skew_T=ds.TTT / ds.TT**1.5,\n",
    "        kurt_T=ds.TTTT / ds.TT**2,\n",
    "    )\n",
    "    ds = ds.drop(\n",
    "        [\n",
    "            \"QCnan\",\n",
    "            \"statU\",\n",
    "            \"statUW\",\n",
    "            \"statWT\",\n",
    "            \"meanU\",\n",
    "            \"meanT\",\n",
    "            \"uu\",\n",
    "            \"vv\",\n",
    "            \"ww\",\n",
    "            \"uv\",\n",
    "            \"uw\",\n",
    "            \"vw\",\n",
    "            \"TT\",\n",
    "            \"uT\",\n",
    "            \"vT\",\n",
    "            \"wT\",\n",
    "            \"tke\",\n",
    "            \"xb\",\n",
    "            \"ustar\",\n",
    "            \"theta\",\n",
    "            \"phi\",\n",
    "            \"uuu\",\n",
    "            \"vvv\",\n",
    "            \"www\",\n",
    "            \"TTT\",\n",
    "            \"uuuu\",\n",
    "            \"vvvv\",\n",
    "            \"wwww\",\n",
    "            \"TTTT\",\n",
    "            \"epsU\",\n",
    "            \"epsV\",\n",
    "            \"epsW\",\n",
    "            \"epsT\",\n",
    "            \"epsUsf\",\n",
    "            \"epsVsf\",\n",
    "            \"epsWsf\",\n",
    "            \"slopeHU\",\n",
    "            \"slopeHV\",\n",
    "            \"slopeHW\",\n",
    "            \"slopeHT\",\n",
    "            \"slopeLU\",\n",
    "            \"slopeLV\",\n",
    "            \"slopeLW\",\n",
    "            \"slopeLT\",\n",
    "            \"sdir\",\n",
    "            \"uuv\",\n",
    "            \"uuw\",\n",
    "            \"uvw\",\n",
    "            \"uvv\",\n",
    "            \"uww\",\n",
    "            \"vvw\",\n",
    "            \"vww\",\n",
    "            \"utke\",\n",
    "            \"vtke\",\n",
    "            \"wtke\",\n",
    "            \"uuT\",\n",
    "            \"vvT\",\n",
    "            \"wwT\",\n",
    "            \"uvT\",\n",
    "            \"uwT\",\n",
    "            \"vwT\",\n",
    "            \"uTT\",\n",
    "            \"vTT\",\n",
    "            \"wTT\",\n",
    "            \"dir\",\n",
    "            \"intlenW\",\n",
    "            \"intlenU\",\n",
    "            \"intlenV\",\n",
    "        ]\n",
    "    )\n",
    "    # merge and return\n",
    "    ds = xr.merge([ds, ffp_stat, trans_stat])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de04c76-bb63-4882-aefc-f1fd5fb5d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_avg = \"30min\"\n",
    "datasets = []\n",
    "\n",
    "for tower_name in tower_names:\n",
    "\n",
    "    # check if there is sonic at 20 m plus tolerance\n",
    "    tower = tower_dict[tower_name]\n",
    "    heights = tower[\"heights_sonic\"]\n",
    "    bool_20m_array = (heights < 21) & (heights > 19)\n",
    "    if True in bool_20m_array:\n",
    "        datasets.append(open_prepare(tower_name, time_avg))\n",
    "\n",
    "\n",
    "ds = xr.concat(datasets, dim=\"tower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796e13a5-4474-4a48-907b-7b7f0b79c60d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"forest_data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81914834-2bba-4c6d-a62c-9556f33b5ad7",
   "metadata": {},
   "source": [
    "## pass to pandas and select groups\n",
    "selected for test 8may B1 middle clouds, 23 may S3 clear sky and 11 june W3 clear sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0b724f4-f62f-4eb8-87b2-445dbbbdb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"forest_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2414627f-c6b2-460d-b132-4f2b9ccc1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack ds\n",
    "ds = (\n",
    "    ds.stack(index=(\"time\", \"tower\"))\n",
    "    .reset_index(\"index\")\n",
    "    .dropna(dim=\"index\", how=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f304bb5-1ade-48f7-bda6-8c9c5f73bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hour that starts the day\n",
    "day_start = 8\n",
    "\n",
    "# Define group labels\n",
    "dates = pd.to_datetime(ds.time)\n",
    "groups = (\n",
    "    dates\n",
    "    - pd.to_datetime(datetime(dates[0].year, dates[0].month, dates[0].day, day_start))\n",
    ").days\n",
    "\n",
    "ds = ds.assign(groups=([\"index\"], groups))\n",
    "\n",
    "# test group\n",
    "test_groups = [7, 22, 41]\n",
    "\n",
    "# split\n",
    "train_bool = np.invert(np.isin(groups, test_groups))\n",
    "groups_train = groups[train_bool]\n",
    "ds_train = ds.where(train_bool).dropna(dim=\"index\")\n",
    "ds_test = ds.where(np.invert(train_bool)).dropna(dim=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a09094bb-987a-471a-984c-476a5a52c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "vars_list = list(ds.data_vars)\n",
    "vars_list.remove(\"yb\")\n",
    "X_train = ds_train.to_dataframe()[vars_list]\n",
    "y_train = ds_train.to_dataframe()[\"yb\"]\n",
    "X_test = ds_test.to_dataframe()[vars_list]\n",
    "y_test = ds_test.to_dataframe()[\"yb\"]\n",
    "\n",
    "\n",
    "# drop groups where not necessary\n",
    "X_test = X_test.drop(columns=\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eb395a6-9e51-4fb3-9ea4-663e48bfde7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "X_train.to_csv(\"xtrain.csv\")\n",
    "y_train.to_csv(\"ytrain.csv\")\n",
    "X_test.to_csv(\"xtest.csv\")\n",
    "y_test.to_csv(\"ytest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4194fabc-d63e-4e01-9e34-b5d1f76dfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv(\"../xtrain.csv\", index_col=0)\n",
    "# y_train = pd.read_csv(\"../ytrain.csv\", index_col=0)\n",
    "# X_test = pd.read_csv(\"../xtest.csv\", index_col=0)\n",
    "# y_test = pd.read_csv(\"../ytest.csv\", index_col=0)\n",
    "# groups = X_train['groups']\n",
    "# X_train = X_train.drop(columns='groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9dfb41-cea3-4d49-b2c6-730843ee2f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd1832-e702-4f68-a4d2-eb2511aba28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
